{
 "cells": [
  {
   "attachments": {
    "a2.jpeg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cliff Walking\n",
    "El agente debe llegar de un punto A a un punto B sin caer en las casillas inferiores, ya que deberia volver al punto A.\n",
    "![a2.jpeg](attachment:a2.jpeg)\n",
    "\n",
    "El agente debe aprender a navegar una cuadr√≠cula de 12x4, en donde las coordenadas horizontales $(2, 1)$, $(3, 1)$, $(4, 1)$, $(5, 1)$, $(6, 1)$, $(7, 1)$, $(8, 1)$, $(9, 1)$, $(10, 1)$, $(11, 1)$ representan un abismo, en el que el agente es penalizado con una recompensa de -100 y debe regresar a la coordenada inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORLD_HEIGHT = 4\n",
    "WORLD_WIDTH = 12\n",
    "START = [4, 1]\n",
    "GOAL = [4, 12];\n",
    "\n",
    "EPSILON = 0.5\n",
    "ALPHA = 0.5\n",
    "GAMMA = 1\n",
    "\n",
    "ACTION_UP = 1\n",
    "ACTION_DOWN = 2\n",
    "ACTION_LEFT = 3\n",
    "ACTION_RIGHT = 4\n",
    "ACTIONS = [ACTION_UP, ACTION_DOWN, ACTION_LEFT, ACTION_RIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function step(state, action)\n",
    "    i, j = state\n",
    "    if action == ACTION_UP\n",
    "        next_state = [max(i - 1, 1), j]\n",
    "    elseif action == ACTION_LEFT\n",
    "        next_state = [i, max(j - 1, 1)]\n",
    "    elseif action == ACTION_RIGHT\n",
    "        next_state = [i, min(j + 1, WORLD_WIDTH)]\n",
    "    elseif action == ACTION_DOWN\n",
    "        next_state = [min(i + 1, WORLD_HEIGHT), j]\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "    \n",
    "    reward = -1\n",
    "    if (action == ACTION_DOWN && i == 3 && 2 <= j && j <= 11) ||\n",
    "        (action == ACTION_RIGHT && state == START)\n",
    "        reward = -100\n",
    "        next_state = START\n",
    "    end\n",
    "    return next_state, reward\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_action (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function choose_action(state, q_value)\n",
    "    if rand(1)[1] < EPSILON\n",
    "        return ACTIONS[rand(1:4)]\n",
    "    else\n",
    "        values_ = q_value[state[1], state[2],:]\n",
    "        action = []\n",
    "        for i in enumerate(values_)\n",
    "            action_,value_ = i\n",
    "            if value_ == maximum(values_)\n",
    "                push!(action,action_)\n",
    "            end\n",
    "        end\n",
    "        action = action[rand(1:length(action))]\n",
    "        return action\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarsa (generic function with 3 methods)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sarsa(q_value, expected = false, step_size = ALPHA)\n",
    "    state = START\n",
    "    action = choose_action(state, q_value)\n",
    "    rewards = 0.0\n",
    "    while state != GOAL\n",
    "        next_state, reward = step(state, action)\n",
    "        next_action = choose_action(next_state,q_value)\n",
    "        rewards += reward\n",
    "        if !expected\n",
    "            target = q_value[next_state[1], next_state[2], next_action]\n",
    "        else\n",
    "            target = 0.0\n",
    "            q_next = q_value[next_state[1], next_state[2], :]\n",
    "            best_actions = transpose(hcat(nonzero(q_next == np.max(q_next))...))\n",
    "            for action_ in ACTIONS\n",
    "                if action_ in best_actions\n",
    "                    target += ((1.0 - EPSILON) / len(best_actions) + EPSILON / len(ACTIONS)) * q_value[next_state[1], next_state[2], action_]\n",
    "                else\n",
    "                    target += EPSILON / len(ACTIONS) * q_value[next_state[1], next_state[2], action_]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        target = target * GAMMA\n",
    "        q_value[state[1], state[2], action] += step_size * (reward + target - q_value[state[1], state[2], action])\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "    end\n",
    "    return rewards\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_learning (generic function with 2 methods)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function q_learning(q_value, step_size = ALPHA)\n",
    "    state = START\n",
    "    rewards = 0.0\n",
    "    while state != GOAL\n",
    "        action = choose_action(state, q_value)\n",
    "        next_state, reward = step(state, action)\n",
    "        rewards += reward\n",
    "\n",
    "        q_value[state[1], state[2], action] += step_size * (\n",
    "                reward + GAMMA * maximum(q_value[next_state[1], next_state[2], :]) -\n",
    "                q_value[state[1], state[2], action])\n",
    "        state = next_state\n",
    "    end\n",
    "    return rewards\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "print_optimal_policy (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function print_optimal_policy(q_value)\n",
    "    optimal_policy = []\n",
    "    for i in range(1, stop=WORLD_HEIGHT)\n",
    "        push!(optimal_policy,[])\n",
    "        for j in range(1, stop=WORLD_WIDTH)\n",
    "            if [i, j] == GOAL\n",
    "                append!(optimal_policy[end], 'G')\n",
    "                continue\n",
    "            end\n",
    "            bestAction = argmax(q_value[i, j, :])\n",
    "            if bestAction == ACTION_UP\n",
    "                append!(optimal_policy[end], '‚Üë')\n",
    "            elseif bestAction == ACTION_DOWN\n",
    "                append!(optimal_policy[end], '‚Üì')\n",
    "            elseif bestAction == ACTION_LEFT\n",
    "                append!(optimal_policy[end], '‚Üê')\n",
    "            elseif bestAction == ACTION_RIGHT\n",
    "                append!(optimal_policy[end], '‚Üí')\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for row in optimal_policy\n",
    "        println(row)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " -4025.94\n",
       " -1495.1 \n",
       " -1152.7 \n",
       "  -656.16\n",
       "  -840.78\n",
       "  -617.62\n",
       "  -591.22\n",
       "  -571.6 \n",
       "  -506.76\n",
       "  -467.28\n",
       "  -442.64\n",
       "  -328.62\n",
       "  -503.78\n",
       "     ‚ãÆ   \n",
       "  -829.1 \n",
       "  -643.06\n",
       "  -664.6 \n",
       "  -669.88\n",
       "  -692.22\n",
       "  -654.78\n",
       "  -661.84\n",
       "  -786.46\n",
       "  -597.9 \n",
       "  -857.92\n",
       "  -954.24\n",
       "  -781.16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes = 500\n",
    "runs = 50\n",
    "\n",
    "rewards_sarsa = zeros(episodes)\n",
    "rewards_q_learning = zeros(episodes)\n",
    "q_sarsa = zeros((world_height, world_width, 4))\n",
    "q_q_learning = deepcopy(q_sarsa)\n",
    "\n",
    "for r ‚àà range(1, runs)\n",
    "    q_sarsa = zeros((world_height, world_width, 4))\n",
    "    q_q_learning = deepcopy(q_sarsa)\n",
    "\n",
    "    for i ‚àà range(1, episodes)\n",
    "        rewards_sarsa[i] += sarsa(q_sarsa)\n",
    "        rewards_q_learning[i] += q_learning(q_q_learning)\n",
    "    end\n",
    "end\n",
    "\n",
    "rewards_sarsa /= runs\n",
    "rewards_q_learning /= runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del aprendizaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarsa:\n",
      "Any['‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üì']\n",
      "Any['‚Üë', '‚Üë', '‚Üë', '‚Üê', '‚Üë', '‚Üí', '‚Üë', '‚Üê', '‚Üí', '‚Üë', '‚Üí', '‚Üì']\n",
      "Any['‚Üë', '‚Üê', '‚Üë', '‚Üë', '‚Üë', '‚Üí', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üí', '‚Üì']\n",
      "Any['‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', 'G']\n",
      "Q-Learning:\n",
      "Any['‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì']\n",
      "Any['‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì', '‚Üì']\n",
      "Any['‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üí', '‚Üì']\n",
      "Any['‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', '‚Üë', 'G']\n"
     ]
    }
   ],
   "source": [
    "println(\"Sarsa:\")\n",
    "print_optimal_policy(q_sarsa)\n",
    "println(\"Q-Learning:\")\n",
    "print_optimal_policy(q_q_learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
